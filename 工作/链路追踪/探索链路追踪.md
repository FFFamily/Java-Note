> ### 秦保科技

应公司框架需求，需要引入 链路追踪

## 引言

### 可观测性

《凤凰架构》有提到  ==可观测性==  这个概念

提出了可观测性的原本含义：可以由其外部输出推断其内部状态的程度

> 这句话比较好理解，系统外部输出的信息能够让我们知道系统内部的一个程序执行情况

也提出了“可观测性”的三个研究方面：==事件日志==、==链路追踪==、==聚合度量==（日志、追踪、度量）

- 日志：记录离散事件
- 追踪：类似单体项目中IDE中的打断点。微服务时代，追踪就不只局限于调用栈了，一个外部请求需要内部若干服务的联动响应

> 微服务的追踪： 也就是说把所有的微服务启动，然后全部DEBUG，在每个方法调用处都打断点。
>
> 这种行为可以称为 “简陋式分布式追踪”

同时引出两个概念：==全链路追踪==、==分布式追踪==

- 度量：对系统中某一类信息的统计聚合

> 关于这一点没能很好的理解，感觉有点类似将数据统一收集，方便查询，类似后面ELK中的ES收集







### 追踪和链路追踪

在对比“追踪”和“链路追踪”时所分析的内容没有很好的理解



追踪方面的情况与日志、度量有所不同，追踪是与具体网络协议、程序语言密切相关的，收集日志不必关心这段日志是由 Java 程序输出的还是由 Golang 程序输出的，对程序来说它们就只是一段非结构化文本而已，同理，度量对程序来说也只是一个个聚合的数据指标而已



但链路追踪就不一样，各个服务之间是使用 HTTP 还是 gRPC 来进行通信会直接影响追踪的实现，各个服务是使用 Java、Golang 还是 Node.js 来编写，也会直接影响到进程内调用栈的追踪方式。这决定了追踪工具本身有较强的侵入性，通常是以插件式的探针来实现；也决定了追踪领域很难出现一家独大的情况，通常要有多种产品来针对不同的语言和网络。



#### 事件日志

> 以下 都是以 ELK为例子展开

《封装架构》中将事件日志归纳为以下几个流程

![](./img/日志处理过程.jpeg)

- **输出**：就是打印日志

- **收集/缓冲**：分布式系统处理一个请求要跨越多个服务节点，为了能看到跨节点的全部日志，就要有能覆盖整个链路的全局日志系统，这个需求决定了每个节点输出日志到文件后，必须将日志文件统一收集起来集中存储、索引，由此便催生了专门的日志收集器。ELK 中常用的就是: Logstash 和 Filebeat

  其中的缓冲就是代表 日志收集器没必要追求全量的收集，而是追求在代价可承受的范围内保证尽可能地保证较高的数据质量。所以在大请求前，可以利用Kafak 或者 Redis 作为缓冲层（消息缓冲队列），缓解收集器的压力

> Filebeat https://github.com/elastic/beats/tree/master/filebeat

- **加工/聚合**：意思就是封装成对应的数据结构，方便查询以及定位
- **存储**：存放日志的地方



#### 链路追踪

谈及链路追踪就离不开 Google 的 论文《Dapper : a Large-Scale Distributed Systems Tracing Infrastructure》,基本所有的链路追踪的框架产品都有受到这个论文的影响

==一个完整的分布式追踪系统应该由数据收集、数据存储和数据展示三个相对独立的子系统构成==

==狭义上讲的追踪则就只是特指链路追踪数据的收集部分，需要配合其他的工具完整的实现ELK==

> 譬如[Spring Cloud Sleuth](https://spring.io/projects/spring-cloud-sleuth)就属于狭义的追踪系统，通常会搭配 Zipkin 作为数据展示，搭配 Elasticsearch 作为数据存储来组合使用，而前面提到的那些 Dapper 的徒子徒孙们大多都属于广义的追踪系统，广义的追踪系统又常被称为“APM 系统”。

> 这个是作为后面分析方案的主要参考依据

##### 追踪与跨度

客户端发起请求抵达系统的边界开始，记录请求流经的每一个服务，直到到向客户端返回响应为止，这整个过程就称为一次“追踪”（）

由于每次 Trace 都可能会调用数量不定、坐标不定的多个服务，为了能够记录具体调用了哪些服务，以及调用的顺序、开始时点、执行时长等信息，每次开始调用服务前都要先埋入一个调用记录，这个记录称为一个“跨度”（Span）



Span 的数据结构应该足够简单，以便于能放在日志或者网络协议的报文头里；也应该足够完备，起码应含有时间戳、起止时间、Trace 的 ID、当前 Span 的 ID、父 Span 的 ID 等能够满足追踪需要的信息



每一次 Trace 实际上都是由若干个有顺序、有层级关系的 Span 所组成一颗“追踪树”



从目标来看，链路追踪的目的是为排查故障和分析性能提供数据支持，系统对外提供服务的过程中，持续地接受请求并处理响应，同时持续地生成 Trace，按次序整理好 Trace 中每一个 Span 所记录的调用关系，便能绘制出一幅系统的服务调用拓扑图。根据拓扑图中 Span 记录的时间信息和响应结果（正常或异常返回）就可以定位到缓慢或者出错的服务；将 Trace 与历史记录进行对比统计，就可以从系统整体层面分析服务性能，定位性能优化的目标。



- **低性能损耗**：分布式追踪不能对服务本身产生明显的性能负担。追踪的主要目的之一就是为了寻找性能缺陷，越慢的服务越是需要追踪，所以工作场景都是性能敏感的地方。
- **对应用透明**：追踪系统通常是运维期才事后加入的系统，应该尽量以非侵入或者少侵入的方式来实现追踪，对开发人员做到透明化。
- **随应用扩缩**：现代的分布式服务集群都有根据流量压力自动扩缩的能力，这要求当业务系统扩缩时，追踪系统也能自动跟随，不需要运维人员人工参与。
- **持续的监控**：要求追踪系统必须能够 7x24 小时工作，否则就难以定位到系统偶尔抖动的行为。



##### 数据收集

追踪系统根据数据收集方式的差异，可分为三种主流的实现方式，分别是**基于日志的追踪**（Log-Based Tracing），**基于服务的追踪**（Service-Based Tracing）和**基于边车代理的追踪**（Sidecar-Based Tracing）

日志追踪

基于日志的追踪的思路是将 Trace、Span 等信息直接输出到应用日志中

日志追踪的代表产品是 Spring Cloud Sleuth

基于服务

基于服务的追踪是目前最为常见的追踪实现方式，被 Zipkin、SkyWalking、Pinpoint 等主流追踪系统广泛采用。服务追踪的实现思路是通过某些手段给目标应用注入追踪探针（Probe），针对 Java 应用一般就是通过 Java Agent 注入的。



#### 聚合度量

不做讨论



### 总结

那么如何实现 “链路追踪” 这样的功能点呢？

我们不会采用 Datadog 这样的商业方案，业务需求没有到那种程度

也不会使用某些云计划厂商的产品，费钱

所以更多的是选择优秀的开源产品：SkyWalking、Zipkin、Jaeger 

下面就会分析不同产品的优缺点，找到适配于公司系统的方案



## ELK

首先能直接了解到的就是 ELK 方案

在分布式系统中，ELK技术栈已经成为日志收集和分析的通用解决方案。需要开发在业务层代码中尽可能的去打印日志

例如

> Log.info("请求开始: {}",request);
>
> // 业务代码
>
> Log.info("请求结束: {}",response);

这样就可以去ES中筛选相关的业务逻辑代码

在美团的文章中指出了其中的缺

> 链接：《可视化全链路日志追踪》

- **日志搜集繁琐**：虽然ES提供了日志检索的能力，但是日志数据往往是缺乏结构性的文本段，很难快速完整地搜集到全部相关的日志。

> 这个缺点感受过
>
> 比如有一套流程 A->B
>
> 日志是这样打印的
>
> log.info(a)  log.info(b)
>
> 那么我在检索的时候就要先搜索A关键字，然后搜索B关键字，这样才能组成一套逻辑

- **日志筛选困难**：不同业务场景、业务逻辑之间存在重叠，重叠逻辑打印的业务日志可能相互干扰，难以从中筛选出正确的关联日志。

> 这个和上一个类似，同样的例子 日志打印A,B
>
> 我去查找A的时候，ES 给我展示的是所有和A相关的日志，我得再次检索出我想要的那一条

- **日志分析耗时**：搜集到的日志只是一条条离散的数据，只能阅读代码，再结合逻辑，由人工对日志进行串联分析，尽可能地还原出现场。

所以美团的评价是：随着业务逻辑和系统复杂度的攀升，传统的ELK方案在日志搜集、日志筛选和日志分析方面愈加的耗时耗力，很难快速实现对业务的追踪









## 参考资料

[1] 凤凰架构：可观测性 ：http://icyfenix.cn/distribution/observability/logging.html

[2] 可视化全链路日志追踪 ：https://juejin.cn/post/7124598702307541023

[3] Dapper : a Large-Scale Distributed Systems Tracing Infrastructure https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf